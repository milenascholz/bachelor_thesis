{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f1ead0-9ae5-4fec-893d-dc266468b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_interactions_df = pd.read_csv('food.com/RAW_interactions.csv', usecols=['user_id', 'recipe_id', 'rating'])\n",
    "raw_recipes_df = pd.read_csv('food.com/RAW_recipes.csv', usecols=['name', 'id', 'tags', 'description'])\n",
    "raw_recipes_df.rename(columns={'id': 'recipe_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e45fe0-4707-4f21-9fa1-c330a460a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove recipes without name/description/tags\n",
    "raw_recipes_df = raw_recipes_df[~raw_recipes_df['description'].isna()]\n",
    "raw_recipes_df = raw_recipes_df[raw_recipes_df['description'].apply(lambda x: any(c.isalpha() for c in x))]\n",
    "raw_recipes_df = raw_recipes_df[~raw_recipes_df['name'].isna()]\n",
    "raw_recipes_df = raw_recipes_df[raw_recipes_df['tags'].apply(lambda x: any(c.isalpha() for c in x))]#226452\n",
    "raw_interactions_df = raw_interactions_df.loc[raw_interactions_df['recipe_id'].isin(raw_recipes_df['recipe_id'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc45fe4c-1766-4ab6-858a-2ef9ea7f2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard users with fewer than 5 reviews\n",
    "raw_interactions_df = raw_interactions_df[raw_interactions_df['user_id'].isin((raw_interactions_df.groupby(by='user_id').size() > 4).where(lambda x: x).dropna().index)] # 23086 users remain\n",
    "raw_recipes_df = raw_recipes_df.loc[raw_recipes_df['recipe_id'].isin(raw_interactions_df['recipe_id'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debd5952-5967-4522-999a-1baf2dd5bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_interactions_df.reset_index(drop=True, inplace=True)\n",
    "raw_recipes_df.sort_values(by='recipe_id', inplace=True)\n",
    "raw_recipes_df.reset_index(drop=True, inplace=True)\n",
    "raw_recipes_df.rename_axis('item_id', inplace=True)\n",
    "\n",
    "itemid_to_recipeid = raw_recipes_df[['recipe_id']].rename_axis('item_id')\n",
    "recipeid_to_itemid = itemid_to_recipeid.reset_index().set_index('recipe_id')\n",
    "\n",
    "raw_interactions_df['item_id'] = recipeid_to_itemid.loc[raw_interactions_df['recipe_id']]['item_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe0ca40-555d-46b5-8423-2d6143f5fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22578 users\n",
    "# 206177 recipes\n",
    "# 851224 interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e46ee-e614-414b-aaf4-f9bb3c3f518d",
   "metadata": {},
   "source": [
    "## CF\n",
    "https://github.com/NicolasHug/Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c0e337-9d3c-4875-812a-f65c0bd9d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7216fe7b-17df-4fa6-8945-7d74ac96b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(raw_interactions_df[[\"user_id\", \"recipe_id\", \"rating\"]], reader)\n",
    "trainset, testset = surprise_train_test_split(data, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f2b1e0-7e5d-4109-98d5-37dd6159eeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0639\n",
      "MAE:  0.5904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5904152785284371"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNNBasic(k=9)\n",
    "\n",
    "knn.fit(trainset)\n",
    "knn_predictions = knn.test(testset)\n",
    "accuracy.rmse(knn_predictions)\n",
    "accuracy.mae(knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d16280-7500-4b80-b5a8-0049c92e85db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9333\n",
      "MAE:  0.5508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5507758441531742"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors=15, lr_all=0.005, n_epochs=18, reg_all=0.04, random_state=7)\n",
    "\n",
    "svd.fit(trainset)\n",
    "svd_predictions = svd.test(testset)\n",
    "accuracy.rmse(svd_predictions)\n",
    "accuracy.mae(svd_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0204ae3-5ea4-4db5-beb6-914adaa77189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# adapted from https://surprise.readthedocs.io/\n",
    "def precision_recall_at_k(predictions, max_k=10, threshold=3.5):\n",
    "    \n",
    "    precision_recall = pd.DataFrame(columns=['k', 'precision', 'recall', 'f-measure']).set_index('k')\n",
    "    \n",
    "    for k in np.arange(1, max_k+1):\n",
    "        # First map the predictions to each user.\n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "            # Sort user ratings by estimated value\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "            # Number of relevant items\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "            # Number of recommended items in top k\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "            # Number of relevant and recommended items in top k\n",
    "            n_rel_and_rec_k = sum(\n",
    "                ((true_r >= threshold) and (est >= threshold))\n",
    "                for (est, true_r) in user_ratings[:k]\n",
    "            )\n",
    "\n",
    "            # Precision@K: Proportion of recommended items that are relevant\n",
    "            # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "            # Recall@K: Proportion of relevant items that are recommended\n",
    "            # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "            \n",
    "        precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "        recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "        f_measure = (2*precision*recall)/(precision+recall)\n",
    "        precision_recall.loc[k] = pd.Series({'precision': precision, 'recall': recall, 'f-measure': f_measure})\n",
    "\n",
    "    return precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1faf3682-a257-4168-ad07-49c95cc68cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_p_r = precision_recall_at_k(knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "011d5c2b-8618-4b62-b327-0c5fa8108cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_p_r = precision_recall_at_k(svd_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b45b389-e870-479f-b05f-40410f2568e5",
   "metadata": {},
   "source": [
    "## CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a2940f01-4f0f-4900-ab07-e4f36bea1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02081973-c6b3-4335-afc7-9e863430cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(words):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    result = []\n",
    "    for word in words:\n",
    "        result.append(stemmer.stem(word.strip(punctuation)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653a7487-06ac-47dc-99dd-1688e362c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    tokens = stem(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47cc0d3a-8f8c-4722-a15f-19cf7ed61eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(df, column_names):\n",
    "    content = df[column_names[0]]\n",
    "    for column_name in column_names[1:]:\n",
    "        content = content + \" \" + df[column_name]\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d53ac463-0b07-4c58-a095-8ac67e16a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_matrix(column_names):\n",
    "    stopword_list = stem(stopwords.words('english')) + [\"\", \"'\", \"'d\", 'could', 'might', 'must', \"n't\", 'need', 'r', 'sha', 'v', 'wo', 'would']\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize,\n",
    "                                 analyzer='word',\n",
    "                                 min_df=0.003,\n",
    "                                 max_df=0.5,\n",
    "                                 stop_words=stopword_list)\n",
    "    tfidf_matrix = vectorizer.fit_transform(get_content(raw_recipes_df, column_names))\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c6fd47-78db-4e1a-9d63-9d150ccc5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_make_predictions():\n",
    "    for user_id in raw_interactions_df['user_id'].unique():\n",
    "    #for user_id in np.array([1634]):\n",
    "        user_train_df = cb_train[cb_train['user_id'] == user_id].sort_values(by='item_id')\n",
    "        user_profile = np.dot(tfidf_matrix[user_train_df['item_id'].values].toarray().T, user_train_df['rating'].values)\n",
    "        \n",
    "        user_test_df = cb_test[cb_test['user_id'] == user_id]\n",
    "        \n",
    "        for item_id in user_test_df['item_id'].values:\n",
    "            user_test_df.loc[(user_test_df['user_id'] == user_id) & (user_test_df['item_id'] == item_id), 'prediction'] = cosine_similarity(np.atleast_2d(user_profile), tfidf_matrix.getrow(item_id))[0][0]\n",
    "        \n",
    "        min = user_test_df['prediction'].min()\n",
    "        max = user_test_df['prediction'].max()\n",
    "        if(max != min):\n",
    "            user_test_df['prediction'] = (user_test_df['prediction'] - min)/(max - min) * 5\n",
    "        \n",
    "        for item_id in user_test_df['item_id'].values:\n",
    "            cb_test.loc[(cb_test['user_id'] == user_id) & (cb_test['item_id'] == item_id), 'prediction'] = user_test_df[user_test_df['item_id'] == item_id]['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "905f824d-58e5-4cbd-861f-644ea482a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://surprise.readthedocs.io/\n",
    "def cb_precision_recall_at_k(max_k=10, threshold=3.5):\n",
    "    \n",
    "    precision_recall = pd.DataFrame(columns=['k', 'precision', 'recall', 'f-measure']).set_index('k')\n",
    "    \n",
    "    for k in np.arange(1, max_k+1):\n",
    "\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        \n",
    "        for user_id in raw_interactions_df['user_id'].unique():#np.array([1634]):\n",
    "            predictions = cb_test[cb_test['user_id'] == user_id].sort_values(by='prediction', ascending=False)\n",
    "            top_k = predictions[:k]\n",
    "            \n",
    "            # Number of relevant items\n",
    "            n_rel = predictions[predictions['rating'] >= threshold].shape[0]\n",
    "\n",
    "            # Number of recommended items in top k\n",
    "            n_rec_k = top_k[top_k['prediction']>= threshold].shape[0]\n",
    "\n",
    "            # Number of relevant and recommended items in top k\n",
    "            n_rel_and_rec_k = top_k[(top_k['prediction'] >= threshold) & (top_k['rating'] >= threshold)].shape[0]\n",
    "\n",
    "            precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "            \n",
    "        precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "        recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "        f_measure = (2*precision*recall)/(precision+recall)\n",
    "        precision_recall.loc[k] = pd.Series({'precision': precision, 'recall': recall, 'f-measure': f_measure})\n",
    "\n",
    "    return precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9f31a33-6879-452c-b323-40368008da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_train, cb_test = train_test_split(raw_interactions_df, test_size=0.25, random_state=7, stratify=raw_interactions_df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afbc60e5-f580-41f9-b750-3d504cff38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = create_tfidf_matrix(['name', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5ce4e69-7032-4d6d-9331-0c004d038b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94175dff-083f-480d-996f-b51bd4cdf1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5262efdf-466d-4ef7-91ec-74d9626cc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_p_r = cb_precision_recall_at_k()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
